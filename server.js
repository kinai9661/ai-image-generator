require('dotenv').config();
const express = require('express');
const path = require('path');
const axios = require('axios');
const app = express();

// ä¸­é—´ä»¶
app.use(express.static('public'));
app.use(express.json({ limit: '50mb' }));

// CORS é…ç½®
app.use((req, res, next) => {
  res.header('Access-Control-Allow-Origin', '*');
  res.header('Access-Control-Allow-Headers', 'Origin, X-Requested-With, Content-Type, Accept');
  next();
});

// ==================== æ¨¡åž‹é…ç½®ç®¡ç† ====================

// é»˜è®¤æ¨¡åž‹é…ç½®ï¼ˆå¦‚æžœæ— æ³•ä»Ž API èŽ·å–ï¼‰
const DEFAULT_MODELS = {
  image: [
    {
      id: 'black-forest-labs/FLUX.1-schnell',
      name: 'FLUX.1 Schnell',
      description: 'âš¡ è¶…å¿«é€Ÿç”Ÿæˆï¼Œ4æ­¥å®Œæˆ',
      provider: 'together',
      maxWidth: 2048,
      maxHeight: 2048,
      free: true,
      speed: 'fast'
    },
    {
      id: 'black-forest-labs/FLUX.1-dev',
      name: 'FLUX.1 Dev',
      description: 'ðŸ”§ å¼€å‘ç‰ˆæœ¬ï¼Œå¹³è¡¡è´¨é‡å’Œé€Ÿåº¦',
      provider: 'together',
      maxWidth: 2048,
      maxHeight: 2048,
      free: true,
      speed: 'medium'
    },
    {
      id: 'black-forest-labs/FLUX.1.1-pro',
      name: 'FLUX.1.1 Pro',
      description: 'ðŸ† ä¸“ä¸šçº§æœ€é«˜å“è´¨',
      provider: 'together',
      maxWidth: 2048,
      maxHeight: 2048,
      free: false,
      speed: 'slow'
    }
  ],
  chat: [
    {
      id: 'meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo',
      name: 'Llama 3.1 405B',
      description: 'ðŸ¦™ Meta æœ€å¼ºå¼€æºæ¨¡åž‹',
      provider: 'together',
      contextWindow: 32768,
      free: true
    },
    {
      id: 'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo',
      name: 'Llama 3.1 70B',
      description: 'âš¡ å¿«é€Ÿå“åº”ï¼Œé«˜è´¨é‡',
      provider: 'together',
      contextWindow: 32768,
      free: true
    },
    {
      id: 'mistralai/Mixtral-8x7B-Instruct-v0.1',
      name: 'Mixtral 8x7B',
      description: 'ðŸ”® Mistral MoE æ¨¡åž‹',
      provider: 'together',
      contextWindow: 32768,
      free: true
    },
    {
      id: 'Qwen/Qwen2.5-72B-Instruct-Turbo',
      name: 'Qwen 2.5 72B',
      description: 'ðŸ‡¨ðŸ‡³ é˜¿é‡Œæœ€æ–°æ¨¡åž‹',
      provider: 'together',
      contextWindow: 32768,
      free: true
    }
  ]
};

// æ¨¡åž‹ç¼“å­˜
let modelCache = {
  image: DEFAULT_MODELS.image,
  chat: DEFAULT_MODELS.chat,
  lastUpdate: null
};

// ä»Ž Together.ai èŽ·å–æœ€æ–°æ¨¡åž‹åˆ—è¡¨
async function fetchTogetherModels() {
  try {
    console.log('ðŸ”„ æ­£åœ¨ä»Ž Together.ai èŽ·å–æœ€æ–°æ¨¡åž‹åˆ—è¡¨...');
    
    const response = await axios.get('https://api.together.xyz/v1/models', {
      headers: {
        'Authorization': `Bearer ${process.env.IMAGE_API_KEY || process.env.CHAT_API_KEY}`
      },
      timeout: 10000
    });

    const models = response.data;
    console.log(`âœ… èŽ·å–åˆ° ${models.length} ä¸ªæ¨¡åž‹`);

    // åˆ†ç±»æ¨¡åž‹
    const imageModels = models
      .filter(m => m.type === 'image' && m.display_name.includes('FLUX'))
      .map(m => ({
        id: m.id,
        name: m.display_name,
        description: m.description || getModelDescription(m.display_name),
        provider: 'together',
        maxWidth: m.config?.max_width || 2048,
        maxHeight: m.config?.max_height || 2048,
        free: !m.pricing || m.pricing.input === 0,
        speed: getModelSpeed(m.display_name)
      }))
      .slice(0, 10);

    const chatModels = models
      .filter(m => m.type === 'chat' && !m.id.includes('moderation'))
      .sort((a, b) => (b.context_length || 0) - (a.context_length || 0))
      .map(m => ({
        id: m.id,
        name: m.display_name,
        description: m.description || getModelDescription(m.display_name),
        provider: 'together',
        contextWindow: m.context_length || 4096,
        free: !m.pricing || m.pricing.input === 0
      }))
      .slice(0, 15);

    if (imageModels.length > 0) modelCache.image = imageModels;
    if (chatModels.length > 0) modelCache.chat = chatModels;
    modelCache.lastUpdate = new Date().toISOString();

    console.log(`âœ… æ¨¡åž‹åˆ—è¡¨å·²æ›´æ–°: ${imageModels.length} ä¸ªå›¾åƒæ¨¡åž‹, ${chatModels.length} ä¸ªèŠå¤©æ¨¡åž‹`);
    
    return { imageModels, chatModels };
  } catch (error) {
    console.error('âŒ èŽ·å– Together.ai æ¨¡åž‹åˆ—è¡¨å¤±è´¥:', error.message);
    console.log('âš ï¸ ä½¿ç”¨é»˜è®¤æ¨¡åž‹é…ç½®');
    return {
      imageModels: DEFAULT_MODELS.image,
      chatModels: DEFAULT_MODELS.chat
    };
  }
}

function getModelDescription(name) {
  if (name.includes('FLUX')) {
    if (name.includes('schnell')) return 'âš¡ è¶…å¿«é€Ÿç”Ÿæˆï¼Œ4æ­¥å®Œæˆ';
    if (name.includes('dev')) return 'ðŸ”§ å¼€å‘ç‰ˆæœ¬ï¼Œå¹³è¡¡è´¨é‡å’Œé€Ÿåº¦';
    if (name.includes('pro')) return 'ðŸ† ä¸“ä¸šçº§æœ€é«˜å“è´¨';
  }
  if (name.includes('Llama')) return 'ðŸ¦™ Meta å¼€æºå¤§è¯­è¨€æ¨¡åž‹';
  if (name.includes('Mixtral')) return 'ðŸ”® Mistral MoE æ¨¡åž‹';
  if (name.includes('Qwen')) return 'ðŸ‡¨ðŸ‡³ é˜¿é‡Œå·´å·´ Qwen æ¨¡åž‹';
  if (name.includes('DeepSeek')) return 'ðŸ¤– DeepSeek æ·±åº¦å­¦ä¹ æ¨¡åž‹';
  return 'ðŸ¤– é«˜æ€§èƒ½ AI æ¨¡åž‹';
}

function getModelSpeed(name) {
  if (name.includes('schnell') || name.includes('turbo')) return 'fast';
  if (name.includes('dev')) return 'medium';
  if (name.includes('pro')) return 'slow';
  return 'medium';
}

// ==================== API ç«¯ç‚¹ ====================

app.get('/api/models', async (req, res) => {
  try {
    const forceRefresh = req.query.refresh === 'true';
    const maxAge = 1000 * 60 * 60;
    
    if (forceRefresh || !modelCache.lastUpdate || 
        (Date.now() - new Date(modelCache.lastUpdate).getTime() > maxAge)) {
      await fetchTogetherModels();
    }

    res.json({
      success: true,
      data: {
        image: modelCache.image,
        chat: modelCache.chat,
        lastUpdate: modelCache.lastUpdate
      },
      cached: !forceRefresh && modelCache.lastUpdate !== null
    });
  } catch (error) {
    res.status(500).json({
      success: false,
      error: error.message,
      data: {
        image: DEFAULT_MODELS.image,
        chat: DEFAULT_MODELS.chat
      }
    });
  }
});

app.get('/api/config', (req, res) => {
  res.json({
    hasImageApi: !!process.env.IMAGE_API_KEY,
    hasChatApi: !!process.env.CHAT_API_KEY,
    provider: 'together',
    features: {
      autoUpdateModels: true,
      batchGeneration: true,
      historyStorage: true
    }
  });
});

app.post('/api/generate-image', async (req, res) => {
  try {
    const { prompt, model, width, height, steps } = req.body;
    
    if (!process.env.IMAGE_API_KEY) {
      return res.status(500).json({ error: 'æœªé…ç½® IMAGE_API_KEY' });
    }

    const response = await axios.post(
      process.env.IMAGE_API_ENDPOINT || 'https://api.together.xyz/v1/images/generations',
      {
        model: model || 'black-forest-labs/FLUX.1-schnell',
        prompt,
        width: width || 1024,
        height: height || 1024,
        steps: steps || 4,
        n: 1,
        response_format: 'b64_json'
      },
      {
        headers: {
          'Authorization': `Bearer ${process.env.IMAGE_API_KEY}`,
          'Content-Type': 'application/json'
        },
        timeout: 120000
      }
    );

    res.json({ success: true, data: response.data.data });
  } catch (error) {
    res.status(500).json({ success: false, error: error.message });
  }
});

app.post('/api/chat', async (req, res) => {
  try {
    const { message, model, history } = req.body;

    if (!process.env.CHAT_API_KEY) {
      return res.status(500).json({ error: 'æœªé…ç½® CHAT_API_KEY' });
    }

    const messages = [
      { role: 'system', content: 'ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„ AI åŠ©æ‰‹ã€‚' },
      ...(history || []),
      { role: 'user', content: message }
    ];

    const response = await axios.post(
      process.env.CHAT_API_ENDPOINT || 'https://api.together.xyz/v1/chat/completions',
      {
        model: model || 'meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo',
        messages,
        temperature: 0.7,
        max_tokens: 2048
      },
      {
        headers: {
          'Authorization': `Bearer ${process.env.CHAT_API_KEY}`,
          'Content-Type': 'application/json'
        },
        timeout: 60000
      }
    );

    res.json({ success: true, data: response.data });
  } catch (error) {
    res.status(500).json({ success: false, error: error.message });
  }
});

app.get('/', (req, res) => {
  res.sendFile(path.join(__dirname, 'public', 'index.html'));
});

app.get('/health', (req, res) => {
  res.json({ 
    status: 'ok',
    timestamp: new Date().toISOString(),
    models: {
      imageCount: modelCache.image.length,
      chatCount: modelCache.chat.length,
      lastUpdate: modelCache.lastUpdate
    }
  });
});

const PORT = process.env.PORT || 3000;

fetchTogetherModels().then(() => {
  app.listen(PORT, () => {
    console.log('ðŸš€ ========================================');
    console.log(`ðŸš€ Server running on port ${PORT}`);
    console.log(`ðŸŽ¨ Image Models: ${modelCache.image.length}`);
    console.log(`ðŸ’¬ Chat Models: ${modelCache.chat.length}`);
    console.log('ðŸš€ ========================================');
  });
});

setInterval(() => {
  fetchTogetherModels();
}, 1000 * 60 * 60);