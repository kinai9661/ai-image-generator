require('dotenv').config();
const express = require('express');
const path = require('path');
const axios = require('axios');
const app = express();

// ä¸­é—´ä»¶
app.use(express.static('public'));
app.use(express.json({ limit: '50mb' }));

// CORS é…ç½®
app.use((req, res, next) => {
  res.header('Access-Control-Allow-Origin', '*');
  res.header('Access-Control-Allow-Headers', 'Origin, X-Requested-With, Content-Type, Accept');
  next();
});

// ==================== æ¨¡åž‹é…ç½®ç®¡ç† ====================

// é»˜è®¤æ¨¡åž‹é…ç½®
const DEFAULT_MODELS = {
  image: [
    {
      id: 'dall-e-3',
      name: 'DALL-E 3',
      description: 'ðŸŽ¨ é«˜è´¨é‡å›¾åƒç”Ÿæˆ',
      provider: 'openai',
      maxWidth: 1024,
      maxHeight: 1024,
      free: false,
      speed: 'medium'
    }
  ],
  chat: [
    {
      id: 'gpt-3.5-turbo',
      name: 'GPT-3.5 Turbo',
      description: 'âš¡ å¿«é€Ÿå“åº”',
      provider: 'openai',
      contextWindow: 4096,
      free: false
    }
  ]
};

// æ¨¡åž‹ç¼“å­˜
let modelCache = {
  image: DEFAULT_MODELS.image,
  chat: DEFAULT_MODELS.chat,
  lastUpdate: null
};

// ä»Ž API ç«¯ç‚¹èŽ·å–æ¨¡åž‹åˆ—è¡¨
async function fetchModelsFromApi() {
  try {
    const modelsEndpoint = process.env.MODELS_API_ENDPOINT;
    
    if (!modelsEndpoint) {
      console.log('âš ï¸ æœªé…ç½® MODELS_API_ENDPOINTï¼Œä½¿ç”¨é»˜è®¤æ¨¡åž‹åˆ—è¡¨');
      return {
        imageModels: DEFAULT_MODELS.image,
        chatModels: DEFAULT_MODELS.chat
      };
    }

    console.log(`ðŸ”„ æ­£åœ¨ä»Ž ${modelsEndpoint} èŽ·å–æ¨¡åž‹åˆ—è¡¨...`);
    
    const apiKey = process.env.IMAGE_API_KEY || process.env.CHAT_API_KEY;
    if (!apiKey) {
      console.log('âš ï¸ æœªé…ç½® API KEYï¼Œä½¿ç”¨é»˜è®¤æ¨¡åž‹åˆ—è¡¨');
      return {
        imageModels: DEFAULT_MODELS.image,
        chatModels: DEFAULT_MODELS.chat
      };
    }

    const response = await axios.get(modelsEndpoint, {
      headers: {
        'Authorization': `Bearer ${apiKey}`
      },
      timeout: 10000
    });

    const models = response.data.data || response.data;
    console.log(`âœ… èŽ·å–åˆ° ${Array.isArray(models) ? models.length : 0} ä¸ªæ¨¡åž‹`);

    if (!Array.isArray(models)) {
      console.warn('âš ï¸ æ¨¡åž‹æ•°æ®æ ¼å¼ä¸æ­£ç¡®ï¼Œä½¿ç”¨é»˜è®¤æ¨¡åž‹');
      return {
        imageModels: DEFAULT_MODELS.image,
        chatModels: DEFAULT_MODELS.chat
      };
    }

    // åˆ†ç±»æ¨¡åž‹
    const imageModels = models
      .filter(m => 
        m.id && (
          m.id.includes('dall-e') || 
          m.id.includes('flux') || 
          m.id.includes('stable-diffusion') ||
          m.id.includes('sdxl') ||
          m.type === 'image'
        )
      )
      .map(m => ({
        id: m.id,
        name: m.name || m.display_name || m.id,
        description: m.description || getModelDescription(m.id),
        provider: detectProvider(m.id),
        maxWidth: 2048,
        maxHeight: 2048,
        free: false,
        speed: getModelSpeed(m.id)
      }))
      .slice(0, 20);

    const chatModels = models
      .filter(m => 
        m.id && (
          m.id.includes('gpt') || 
          m.id.includes('llama') || 
          m.id.includes('claude') || 
          m.id.includes('qwen') ||
          m.id.includes('grok') ||
          m.id.includes('mixtral') ||
          m.type === 'chat' || 
          m.type === 'text'
        )
      )
      .map(m => ({
        id: m.id,
        name: m.name || m.display_name || m.id,
        description: m.description || getModelDescription(m.id),
        provider: detectProvider(m.id),
        contextWindow: m.context_length || 4096,
        free: false
      }))
      .slice(0, 30);

    if (imageModels.length > 0) modelCache.image = imageModels;
    if (chatModels.length > 0) modelCache.chat = chatModels;
    modelCache.lastUpdate = new Date().toISOString();

    console.log(`âœ… æ¨¡åž‹åˆ—è¡¨å·²æ›´æ–°: ${imageModels.length} ä¸ªå›¾åƒæ¨¡åž‹, ${chatModels.length} ä¸ªèŠå¤©æ¨¡åž‹`);
    
    return { imageModels, chatModels };
  } catch (error) {
    console.error('âŒ èŽ·å–æ¨¡åž‹åˆ—è¡¨å¤±è´¥:', error.message);
    console.log('âš ï¸ ä½¿ç”¨é»˜è®¤æ¨¡åž‹é…ç½®');
    return {
      imageModels: DEFAULT_MODELS.image,
      chatModels: DEFAULT_MODELS.chat
    };
  }
}

function detectProvider(modelId) {
  if (!modelId) return 'unknown';
  const id = modelId.toLowerCase();
  if (id.includes('gpt') || id.includes('dall-e')) return 'openai';
  if (id.includes('claude')) return 'anthropic';
  if (id.includes('llama')) return 'meta';
  if (id.includes('mixtral') || id.includes('mistral')) return 'mistral';
  if (id.includes('qwen')) return 'alibaba';
  if (id.includes('grok')) return 'xai';
  if (id.includes('flux')) return 'black-forest-labs';
  if (id.includes('stable-diffusion') || id.includes('sdxl')) return 'stability';
  return 'custom';
}

function getModelDescription(name) {
  if (!name) return 'ðŸ¤– AI æ¨¡åž‹';
  const n = name.toLowerCase();
  if (n.includes('gpt-4')) return 'ðŸ¤– OpenAI æœ€å¼ºæ¨¡åž‹';
  if (n.includes('gpt-3.5')) return 'âš¡ å¿«é€Ÿå“åº”';
  if (n.includes('dall-e-3')) return 'ðŸŽ¨ é«˜è´¨é‡å›¾åƒç”Ÿæˆ';
  if (n.includes('dall-e-2')) return 'âš¡ å¿«é€Ÿå›¾åƒç”Ÿæˆ';
  if (n.includes('grok')) return 'ðŸš€ xAI Grok æ¨¡åž‹';
  if (n.includes('flux')) {
    if (n.includes('schnell')) return 'âš¡ è¶…å¿«é€Ÿç”Ÿæˆ';
    if (n.includes('dev')) return 'ðŸ”§ å¼€å‘ç‰ˆæœ¬';
    if (n.includes('pro')) return 'ðŸ† ä¸“ä¸šçº§å“è´¨';
    return 'ðŸŽ¨ FLUX å›¾åƒæ¨¡åž‹';
  }
  if (n.includes('llama')) return 'ðŸ¦™ Meta å¼€æºæ¨¡åž‹';
  if (n.includes('claude')) return 'ðŸ¤– Anthropic Claude';
  if (n.includes('qwen')) return 'ðŸ‡¨ðŸ‡³ é˜¿é‡Œå·´å·´ Qwen';
  if (n.includes('mixtral')) return 'ðŸ”® Mistral MoE';
  if (n.includes('stable-diffusion') || n.includes('sdxl')) return 'ðŸŽ¨ Stable Diffusion';
  return 'ðŸ¤– AI æ¨¡åž‹';
}

function getModelSpeed(name) {
  if (!name) return 'medium';
  const n = name.toLowerCase();
  if (n.includes('schnell') || n.includes('turbo') || n.includes('fast')) return 'fast';
  if (n.includes('dall-e-2') || n.includes('gpt-3.5')) return 'fast';
  if (n.includes('dev') || n.includes('base')) return 'medium';
  if (n.includes('pro') || n.includes('gpt-4') || n.includes('claude')) return 'slow';
  return 'medium';
}

// ==================== API ç«¯ç‚¹ ====================

app.get('/api/models', async (req, res) => {
  try {
    const forceRefresh = req.query.refresh === 'true';
    const maxAge = 1000 * 60 * 60;
    
    if (forceRefresh || !modelCache.lastUpdate || 
        (Date.now() - new Date(modelCache.lastUpdate).getTime() > maxAge)) {
      await fetchModelsFromApi();
    }

    res.json({
      success: true,
      data: {
        image: modelCache.image,
        chat: modelCache.chat,
        lastUpdate: modelCache.lastUpdate
      },
      cached: !forceRefresh && modelCache.lastUpdate !== null
    });
  } catch (error) {
    res.status(500).json({
      success: false,
      error: error.message,
      data: {
        image: DEFAULT_MODELS.image,
        chat: DEFAULT_MODELS.chat
      }
    });
  }
});

app.get('/api/config', (req, res) => {
  res.json({
    hasImageApi: !!process.env.IMAGE_API_KEY,
    hasChatApi: !!process.env.CHAT_API_KEY,
    provider: process.env.API_PROVIDER || 'generic',
    features: {
      autoUpdateModels: !!process.env.MODELS_API_ENDPOINT,
      batchGeneration: false,
      historyStorage: true
    }
  });
});

// å›¾åƒç”Ÿæˆ API ä»£ç†
app.post('/api/generate-image', async (req, res) => {
  try {
    const { prompt, model, width, height } = req.body;
    
    if (!process.env.IMAGE_API_KEY) {
      return res.status(500).json({ 
        success: false,
        error: 'æœªé…ç½® IMAGE_API_KEY' 
      });
    }

    console.log(`ðŸŽ¨ å›¾åƒç”Ÿæˆè¯·æ±‚: ${prompt.substring(0, 50)}...`);
    console.log(`ðŸŽ¯ æ¨¡åž‹: ${model}, å°ºå¯¸: ${width}x${height}`);

    const endpoint = process.env.IMAGE_API_ENDPOINT || 'https://api.openai.com/v1/images/generations';
    
    // æž„å»ºè¯·æ±‚ä½“ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
    let requestBody;
    
    // åˆ¤æ–­ API æä¾›å•†ç±»åž‹
    if (endpoint.includes('together.xyz')) {
      // Together.ai æ ¼å¼
      requestBody = {
        model: model || 'black-forest-labs/FLUX.1-schnell',
        prompt,
        width: width || 1024,
        height: height || 1024,
        steps: 4,
        n: 1,
        response_format: 'b64_json'
      };
    } else {
      // é€šç”¨ OpenAI å…¼å®¹æ ¼å¼ï¼ˆé€‚ç”¨äºŽ Typliã€OpenAI ç­‰ï¼‰
      requestBody = {
        prompt,
        model: model || 'dall-e-3',
        n: 1,
        size: `${width || 1024}x${height || 1024}`,
        response_format: 'b64_json'
      };
    }

    console.log('ðŸ“¤ è¯·æ±‚ä½“:', JSON.stringify(requestBody, null, 2));

    const response = await axios.post(endpoint, requestBody, {
      headers: {
        'Authorization': `Bearer ${process.env.IMAGE_API_KEY}`,
        'Content-Type': 'application/json'
      },
      timeout: 120000,
      validateStatus: (status) => status < 500 // æŽ¥å— 400-499 é”™è¯¯ï¼Œä½†ä¸æŠ›å‡ºå¼‚å¸¸
    });

    console.log(`ðŸ“ å“åº”çŠ¶æ€: ${response.status}`);

    if (response.status >= 400) {
      // å¤„ç† 4xx é”™è¯¯
      const errorData = response.data;
      console.error('âŒ API è¿”å›žé”™è¯¯:', errorData);
      
      let errorMessage = 'å›¾åƒç”Ÿæˆå¤±è´¥';
      if (errorData.error) {
        if (typeof errorData.error === 'string') {
          errorMessage = errorData.error;
        } else if (errorData.error.message) {
          errorMessage = errorData.error.message;
        }
      }
      
      return res.status(response.status).json({ 
        success: false,
        error: errorMessage,
        details: errorData
      });
    }

    console.log('âœ… å›¾åƒç”ŸæˆæˆåŠŸ');
    
    res.json({ 
      success: true, 
      data: response.data.data || response.data
    });

  } catch (error) {
    console.error('âŒ å›¾åƒç”Ÿæˆå¤±è´¥:', error.message);
    if (error.response) {
      console.error('âŒ API å“åº”é”™è¯¯:', error.response.data);
    }
    
    let errorMessage = 'å›¾åƒç”Ÿæˆå¤±è´¥';
    if (error.response?.data?.error) {
      const err = error.response.data.error;
      errorMessage = typeof err === 'string' ? err : (err.message || errorMessage);
    } else if (error.code === 'ECONNABORTED') {
      errorMessage = 'è¯·æ±‚è¶…æ—¶ï¼Œè¯·é‡è¯•';
    } else if (error.message) {
      errorMessage = error.message;
    }

    res.status(error.response?.status || 500).json({ 
      success: false,
      error: errorMessage
    });
  }
});

// AI èŠå¤© API ä»£ç†
app.post('/api/chat', async (req, res) => {
  try {
    const { message, model, history } = req.body;

    if (!process.env.CHAT_API_KEY) {
      return res.status(500).json({ 
        success: false,
        error: 'æœªé…ç½® CHAT_API_KEY' 
      });
    }

    console.log(`ðŸ’¬ èŠå¤©è¯·æ±‚: ${message.substring(0, 50)}...`);
    console.log(`ðŸŽ¯ æ¨¡åž‹: ${model}`);

    const endpoint = process.env.CHAT_API_ENDPOINT || 'https://api.openai.com/v1/chat/completions';
    
    // æž„å»ºæ¶ˆæ¯åŽ†å²
    const messages = [
      { role: 'system', content: 'ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„ AI åŠ©æ‰‹ã€‚' },
      ...(history || []),
      { role: 'user', content: message }
    ];

    console.log(`ðŸ“¤ æ¶ˆæ¯æ•°é‡: ${messages.length}`);

    const response = await axios.post(endpoint, {
      model: model || 'gpt-3.5-turbo',
      messages,
      temperature: 0.7,
      max_tokens: 2048
    }, {
      headers: {
        'Authorization': `Bearer ${process.env.CHAT_API_KEY}`,
        'Content-Type': 'application/json'
      },
      timeout: 60000,
      validateStatus: (status) => status < 500
    });

    console.log(`ðŸ“ å“åº”çŠ¶æ€: ${response.status}`);

    if (response.status >= 400) {
      const errorData = response.data;
      console.error('âŒ API è¿”å›žé”™è¯¯:', errorData);
      
      let errorMessage = 'èŠå¤©å¤±è´¥';
      if (errorData.error) {
        if (typeof errorData.error === 'string') {
          errorMessage = errorData.error;
        } else if (errorData.error.message) {
          errorMessage = errorData.error.message;
        }
      }
      
      return res.status(response.status).json({ 
        success: false,
        error: errorMessage,
        details: errorData
      });
    }

    console.log('âœ… èŠå¤©å“åº”æˆåŠŸ');
    res.json({
      success: true,
      data: response.data
    });

  } catch (error) {
    console.error('âŒ èŠå¤©å¤±è´¥:', error.message);
    if (error.response) {
      console.error('âŒ API å“åº”é”™è¯¯:', error.response.data);
    }
    
    let errorMessage = 'èŠå¤©å¤±è´¥';
    if (error.response?.data?.error) {
      const err = error.response.data.error;
      errorMessage = typeof err === 'string' ? err : (err.message || errorMessage);
    } else if (error.message) {
      errorMessage = error.message;
    }

    res.status(error.response?.status || 500).json({ 
      success: false,
      error: errorMessage
    });
  }
});

app.get('/', (req, res) => {
  res.sendFile(path.join(__dirname, 'public', 'index.html'));
});

app.get('/health', (req, res) => {
  res.json({ 
    status: 'ok',
    timestamp: new Date().toISOString(),
    config: {
      hasImageApi: !!process.env.IMAGE_API_KEY,
      hasChatApi: !!process.env.CHAT_API_KEY,
      provider: process.env.API_PROVIDER || 'generic',
      endpoints: {
        image: process.env.IMAGE_API_ENDPOINT || 'not configured',
        chat: process.env.CHAT_API_ENDPOINT || 'not configured',
        models: process.env.MODELS_API_ENDPOINT || 'not configured'
      }
    },
    models: {
      imageCount: modelCache.image.length,
      chatCount: modelCache.chat.length,
      lastUpdate: modelCache.lastUpdate
    }
  });
});

// ==================== å¯åŠ¨æœåŠ¡å™¨ ====================
const PORT = process.env.PORT || 3000;

fetchModelsFromApi().then(() => {
  app.listen(PORT, () => {
    console.log('ðŸš€ ========================================');
    console.log(`ðŸš€ Server running on port ${PORT}`);
    console.log(`ðŸ“ Environment: ${process.env.NODE_ENV || 'development'}`);
    console.log(`ðŸŽ¨ Image API: ${process.env.IMAGE_API_KEY ? 'âœ… Configured' : 'âŒ Not configured'}`);
    console.log(`ðŸ’¬ Chat API: ${process.env.CHAT_API_KEY ? 'âœ… Configured' : 'âŒ Not configured'}`);
    console.log(`ðŸ”— Image Endpoint: ${process.env.IMAGE_API_ENDPOINT || 'default'}`);
    console.log(`ðŸ”— Chat Endpoint: ${process.env.CHAT_API_ENDPOINT || 'default'}`);
    console.log(`ðŸ¤– Image Models: ${modelCache.image.length}`);
    console.log(`ðŸ’¬ Chat Models: ${modelCache.chat.length}`);
    console.log('ðŸš€ ========================================');
  });
});

if (process.env.MODELS_API_ENDPOINT) {
  setInterval(() => {
    console.log('ðŸ”„ å®šæœŸæ›´æ–°æ¨¡åž‹åˆ—è¡¨...');
    fetchModelsFromApi();
  }, 1000 * 60 * 60);
}