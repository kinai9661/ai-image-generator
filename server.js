require('dotenv').config();
const express = require('express');
const path = require('path');
const axios = require('axios');
const app = express();

// ä¸­é—´ä»¶
app.use(express.static('public'));
app.use(express.json({ limit: '50mb' }));

// CORS é…ç½®
app.use((req, res, next) => {
  res.header('Access-Control-Allow-Origin', '*');
  res.header('Access-Control-Allow-Headers', 'Origin, X-Requested-With, Content-Type, Accept');
  next();
});

// ==================== æ¨¡åž‹é…ç½®ç®¡ç† ====================

// é»˜è®¤æ¨¡åž‹é…ç½®ï¼ˆé€šç”¨ï¼‰
const DEFAULT_MODELS = {
  image: [
    {
      id: 'dall-e-3',
      name: 'DALL-E 3',
      description: 'ðŸŽ¨ OpenAI æœ€æ–°å›¾åƒæ¨¡åž‹',
      provider: 'openai',
      maxWidth: 1024,
      maxHeight: 1024,
      free: false,
      speed: 'medium'
    },
    {
      id: 'dall-e-2',
      name: 'DALL-E 2',
      description: 'âš¡ å¿«é€Ÿå›¾åƒç”Ÿæˆ',
      provider: 'openai',
      maxWidth: 1024,
      maxHeight: 1024,
      free: false,
      speed: 'fast'
    }
  ],
  chat: [
    {
      id: 'gpt-4',
      name: 'GPT-4',
      description: 'ðŸ¤– OpenAI æœ€å¼ºæ¨¡åž‹',
      provider: 'openai',
      contextWindow: 8192,
      free: false
    },
    {
      id: 'gpt-3.5-turbo',
      name: 'GPT-3.5 Turbo',
      description: 'âš¡ å¿«é€Ÿå“åº”',
      provider: 'openai',
      contextWindow: 4096,
      free: false
    }
  ]
};

// æ¨¡åž‹ç¼“å­˜
let modelCache = {
  image: DEFAULT_MODELS.image,
  chat: DEFAULT_MODELS.chat,
  lastUpdate: null
};

// ä»Ž API ç«¯ç‚¹èŽ·å–æ¨¡åž‹åˆ—è¡¨ï¼ˆæ”¯æŒ OpenAI å…¼å®¹çš„ /v1/models ç«¯ç‚¹ï¼‰
async function fetchModelsFromApi() {
  try {
    // æ£€æŸ¥æ˜¯å¦é…ç½®äº†æ¨¡åž‹ API ç«¯ç‚¹
    const modelsEndpoint = process.env.MODELS_API_ENDPOINT;
    
    if (!modelsEndpoint) {
      console.log('âš ï¸ æœªé…ç½® MODELS_API_ENDPOINTï¼Œä½¿ç”¨é»˜è®¤æ¨¡åž‹åˆ—è¡¨');
      return {
        imageModels: DEFAULT_MODELS.image,
        chatModels: DEFAULT_MODELS.chat
      };
    }

    console.log(`ðŸ”„ æ­£åœ¨ä»Ž ${modelsEndpoint} èŽ·å–æ¨¡åž‹åˆ—è¡¨...`);
    
    const apiKey = process.env.IMAGE_API_KEY || process.env.CHAT_API_KEY;
    if (!apiKey) {
      console.log('âš ï¸ æœªé…ç½® API KEYï¼Œä½¿ç”¨é»˜è®¤æ¨¡åž‹åˆ—è¡¨');
      return {
        imageModels: DEFAULT_MODELS.image,
        chatModels: DEFAULT_MODELS.chat
      };
    }

    const response = await axios.get(modelsEndpoint, {
      headers: {
        'Authorization': `Bearer ${apiKey}`
      },
      timeout: 10000
    });

    const models = response.data.data || response.data;
    console.log(`âœ… èŽ·å–åˆ° ${models.length} ä¸ªæ¨¡åž‹`);

    // åˆ†ç±»æ¨¡åž‹ï¼ˆæ ¹æ® id æˆ– type å­—æ®µï¼‰
    const imageModels = models
      .filter(m => 
        (m.id && (m.id.includes('dall-e') || m.id.includes('flux') || m.id.includes('stable-diffusion'))) ||
        (m.type === 'image')
      )
      .map(m => ({
        id: m.id,
        name: m.name || m.display_name || m.id,
        description: m.description || getModelDescription(m.id),
        provider: detectProvider(m.id),
        maxWidth: 2048,
        maxHeight: 2048,
        free: false,
        speed: getModelSpeed(m.id)
      }))
      .slice(0, 10);

    const chatModels = models
      .filter(m => 
        (m.id && (m.id.includes('gpt') || m.id.includes('llama') || m.id.includes('claude') || m.id.includes('qwen'))) ||
        (m.type === 'chat' || m.type === 'text')
      )
      .map(m => ({
        id: m.id,
        name: m.name || m.display_name || m.id,
        description: m.description || getModelDescription(m.id),
        provider: detectProvider(m.id),
        contextWindow: m.context_length || 4096,
        free: false
      }))
      .slice(0, 15);

    if (imageModels.length > 0) modelCache.image = imageModels;
    if (chatModels.length > 0) modelCache.chat = chatModels;
    modelCache.lastUpdate = new Date().toISOString();

    console.log(`âœ… æ¨¡åž‹åˆ—è¡¨å·²æ›´æ–°: ${imageModels.length} ä¸ªå›¾åƒæ¨¡åž‹, ${chatModels.length} ä¸ªèŠå¤©æ¨¡åž‹`);
    
    return { imageModels, chatModels };
  } catch (error) {
    console.error('âŒ èŽ·å–æ¨¡åž‹åˆ—è¡¨å¤±è´¥:', error.message);
    console.log('âš ï¸ ä½¿ç”¨é»˜è®¤æ¨¡åž‹é…ç½®');
    return {
      imageModels: DEFAULT_MODELS.image,
      chatModels: DEFAULT_MODELS.chat
    };
  }
}

function detectProvider(modelId) {
  if (!modelId) return 'unknown';
  const id = modelId.toLowerCase();
  if (id.includes('gpt') || id.includes('dall-e')) return 'openai';
  if (id.includes('claude')) return 'anthropic';
  if (id.includes('llama')) return 'meta';
  if (id.includes('mixtral') || id.includes('mistral')) return 'mistral';
  if (id.includes('qwen')) return 'alibaba';
  if (id.includes('flux')) return 'black-forest-labs';
  if (id.includes('stable-diffusion')) return 'stability';
  return 'custom';
}

function getModelDescription(name) {
  if (!name) return 'ðŸ¤– AI æ¨¡åž‹';
  const n = name.toLowerCase();
  if (n.includes('gpt-4')) return 'ðŸ¤– OpenAI æœ€å¼ºæ¨¡åž‹';
  if (n.includes('gpt-3.5')) return 'âš¡ å¿«é€Ÿå“åº”';
  if (n.includes('dall-e-3')) return 'ðŸŽ¨ é«˜è´¨é‡å›¾åƒç”Ÿæˆ';
  if (n.includes('dall-e-2')) return 'âš¡ å¿«é€Ÿå›¾åƒç”Ÿæˆ';
  if (n.includes('flux')) {
    if (n.includes('schnell')) return 'âš¡ è¶…å¿«é€Ÿç”Ÿæˆ';
    if (n.includes('dev')) return 'ðŸ”§ å¼€å‘ç‰ˆæœ¬';
    if (n.includes('pro')) return 'ðŸ† ä¸“ä¸šçº§å“è´¨';
    return 'ðŸŽ¨ FLUX å›¾åƒæ¨¡åž‹';
  }
  if (n.includes('llama')) return 'ðŸ¦™ Meta å¼€æºæ¨¡åž‹';
  if (n.includes('claude')) return 'ðŸ¤– Anthropic Claude';
  if (n.includes('qwen')) return 'ðŸ‡¨ðŸ‡³ é˜¿é‡Œå·´å·´ Qwen';
  if (n.includes('mixtral')) return 'ðŸ”® Mistral MoE';
  return 'ðŸ¤– AI æ¨¡åž‹';
}

function getModelSpeed(name) {
  if (!name) return 'medium';
  const n = name.toLowerCase();
  if (n.includes('schnell') || n.includes('turbo') || n.includes('fast')) return 'fast';
  if (n.includes('dall-e-2') || n.includes('gpt-3.5')) return 'fast';
  if (n.includes('dev') || n.includes('base')) return 'medium';
  if (n.includes('pro') || n.includes('gpt-4') || n.includes('claude')) return 'slow';
  return 'medium';
}

// ==================== API ç«¯ç‚¹ ====================

app.get('/api/models', async (req, res) => {
  try {
    const forceRefresh = req.query.refresh === 'true';
    const maxAge = 1000 * 60 * 60; // 1å°æ—¶ç¼“å­˜
    
    if (forceRefresh || !modelCache.lastUpdate || 
        (Date.now() - new Date(modelCache.lastUpdate).getTime() > maxAge)) {
      await fetchModelsFromApi();
    }

    res.json({
      success: true,
      data: {
        image: modelCache.image,
        chat: modelCache.chat,
        lastUpdate: modelCache.lastUpdate
      },
      cached: !forceRefresh && modelCache.lastUpdate !== null
    });
  } catch (error) {
    res.status(500).json({
      success: false,
      error: error.message,
      data: {
        image: DEFAULT_MODELS.image,
        chat: DEFAULT_MODELS.chat
      }
    });
  }
});

app.get('/api/config', (req, res) => {
  res.json({
    hasImageApi: !!process.env.IMAGE_API_KEY,
    hasChatApi: !!process.env.CHAT_API_KEY,
    provider: process.env.API_PROVIDER || 'generic',
    features: {
      autoUpdateModels: !!process.env.MODELS_API_ENDPOINT,
      batchGeneration: false,
      historyStorage: true
    }
  });
});

// å›¾åƒç”Ÿæˆ API ä»£ç†ï¼ˆæ”¯æŒ OpenAI å…¼å®¹æ ¼å¼ï¼‰
app.post('/api/generate-image', async (req, res) => {
  try {
    const { prompt, model, width, height } = req.body;
    
    if (!process.env.IMAGE_API_KEY) {
      return res.status(500).json({ 
        success: false,
        error: 'æœªé…ç½® IMAGE_API_KEY' 
      });
    }

    console.log(`ðŸŽ¨ å›¾åƒç”Ÿæˆè¯·æ±‚: ${prompt.substring(0, 50)}...`);

    // é»˜è®¤ä½¿ç”¨ OpenAI æ ¼å¼
    const endpoint = process.env.IMAGE_API_ENDPOINT || 'https://api.openai.com/v1/images/generations';
    
    // æž„å»ºè¯·æ±‚ä½“ï¼ˆOpenAI å…¼å®¹æ ¼å¼ï¼‰
    const requestBody = {
      prompt,
      model: model || 'dall-e-3',
      n: 1,
      size: `${width || 1024}x${height || 1024}`,
      response_format: 'b64_json'
    };

    const response = await axios.post(endpoint, requestBody, {
      headers: {
        'Authorization': `Bearer ${process.env.IMAGE_API_KEY}`,
        'Content-Type': 'application/json'
      },
      timeout: 120000
    });

    console.log('âœ… å›¾åƒç”ŸæˆæˆåŠŸ');
    res.json({ 
      success: true, 
      data: response.data.data 
    });

  } catch (error) {
    console.error('âŒ å›¾åƒç”Ÿæˆå¤±è´¥:', error.message);
    
    let errorMessage = 'å›¾åƒç”Ÿæˆå¤±è´¥';
    if (error.response?.data?.error) {
      errorMessage = error.response.data.error.message || error.response.data.error;
    } else if (error.code === 'ECONNABORTED') {
      errorMessage = 'è¯·æ±‚è¶…æ—¶ï¼Œè¯·é‡è¯•';
    } else if (error.message) {
      errorMessage = error.message;
    }

    res.status(error.response?.status || 500).json({ 
      success: false,
      error: errorMessage
    });
  }
});

// AI èŠå¤© API ä»£ç†ï¼ˆæ”¯æŒ OpenAI å…¼å®¹æ ¼å¼ï¼‰
app.post('/api/chat', async (req, res) => {
  try {
    const { message, model, history } = req.body;

    if (!process.env.CHAT_API_KEY) {
      return res.status(500).json({ 
        success: false,
        error: 'æœªé…ç½® CHAT_API_KEY' 
      });
    }

    console.log(`ðŸ’¬ èŠå¤©è¯·æ±‚: ${message.substring(0, 50)}...`);

    // é»˜è®¤ä½¿ç”¨ OpenAI æ ¼å¼
    const endpoint = process.env.CHAT_API_ENDPOINT || 'https://api.openai.com/v1/chat/completions';
    
    // æž„å»ºæ¶ˆæ¯åŽ†å²
    const messages = [
      { role: 'system', content: 'ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„ AI åŠ©æ‰‹ã€‚' },
      ...(history || []),
      { role: 'user', content: message }
    ];

    const response = await axios.post(endpoint, {
      model: model || 'gpt-3.5-turbo',
      messages,
      temperature: 0.7,
      max_tokens: 2048
    }, {
      headers: {
        'Authorization': `Bearer ${process.env.CHAT_API_KEY}`,
        'Content-Type': 'application/json'
      },
      timeout: 60000
    });

    console.log('âœ… èŠå¤©å“åº”æˆåŠŸ');
    res.json({
      success: true,
      data: response.data
    });

  } catch (error) {
    console.error('âŒ èŠå¤©å¤±è´¥:', error.message);
    
    let errorMessage = 'èŠå¤©å¤±è´¥';
    if (error.response?.data?.error) {
      errorMessage = error.response.data.error.message || error.response.data.error;
    } else if (error.message) {
      errorMessage = error.message;
    }

    res.status(error.response?.status || 500).json({ 
      success: false,
      error: errorMessage
    });
  }
});

app.get('/', (req, res) => {
  res.sendFile(path.join(__dirname, 'public', 'index.html'));
});

app.get('/health', (req, res) => {
  res.json({ 
    status: 'ok',
    timestamp: new Date().toISOString(),
    config: {
      hasImageApi: !!process.env.IMAGE_API_KEY,
      hasChatApi: !!process.env.CHAT_API_KEY,
      provider: process.env.API_PROVIDER || 'generic'
    },
    models: {
      imageCount: modelCache.image.length,
      chatCount: modelCache.chat.length,
      lastUpdate: modelCache.lastUpdate
    }
  });
});

// ==================== å¯åŠ¨æœåŠ¡å™¨ ====================
const PORT = process.env.PORT || 3000;

// å¯åŠ¨æ—¶å°è¯•åŠ è½½æ¨¡åž‹åˆ—è¡¨ï¼ˆå¦‚æžœé…ç½®äº†ï¼‰
fetchModelsFromApi().then(() => {
  app.listen(PORT, () => {
    console.log('ðŸš€ ========================================');
    console.log(`ðŸš€ Server running on port ${PORT}`);
    console.log(`ðŸ“ Environment: ${process.env.NODE_ENV || 'development'}`);
    console.log(`ðŸŽ¨ Image API: ${process.env.IMAGE_API_KEY ? 'âœ… Configured' : 'âŒ Not configured'}`);
    console.log(`ðŸ’¬ Chat API: ${process.env.CHAT_API_KEY ? 'âœ… Configured' : 'âŒ Not configured'}`);
    console.log(`ðŸ¤– Image Models: ${modelCache.image.length}`);
    console.log(`ðŸ’¬ Chat Models: ${modelCache.chat.length}`);
    console.log('ðŸš€ ========================================');
  });
});

// å®šæœŸæ›´æ–°æ¨¡åž‹åˆ—è¡¨ï¼ˆæ¯å°æ—¶ï¼‰
if (process.env.MODELS_API_ENDPOINT) {
  setInterval(() => {
    console.log('ðŸ”„ å®šæœŸæ›´æ–°æ¨¡åž‹åˆ—è¡¨...');
    fetchModelsFromApi();
  }, 1000 * 60 * 60);
}